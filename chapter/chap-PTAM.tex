
\def \R2{\mathbb{R}^2}
\def \R3{\mathbb{R}^3}
\def \Rn{\mathbb{R}^n}

\def \itW{\mathit{W}}

\def \itK{\mathit{K}}
\def \bfp{\mathbf{p}}

\chapter{基于单目相机的3维实时重建的PTAM算法介绍}

\section{数学知识介绍}

\section{PTAM算法的介绍}
关键词，双管线系统，为后面的算法奠定了基础

\section{PTAM算法的数学推导}
我们首先简述PTAM实现单目相机SLAM的原理。单目相机模型不同于双目相机，实时追踪时相机视界中的点不能和其它相机视界中的点进行匹配，只能和自己的关键帧匹配，从而加大了3D重建中定位的难度。PTAM算法提出利用单目相机实时追踪特征点的可行性，实现三维重建。

\subsection{PTAM算法工作的基本流程}
PTAM算法主要思想是将Tracking和Mapping两个过程放在不同的管线(进程)中进行: Tracking 进程专门实现相机位置的估计，Mapping 进程则用于进行关键帧之间的误差消除。

如果记$\itW$为真实世界的坐标系，PTAM算法将维护一个关键帧集合: $Img=\{I_1,I_2,\ldots,I_m\}$，这\(m\)个关键帧分别对应\(m\)个相机坐标系 $\itK_i$。我们用 $E_{\itK_i\itW}$ 表示从世界坐标系到相机坐标系的仿射变换(Affine Transformation)。

\subsection{PTAM管线之一: Tracking}

%
% Todo: 插入一张流程图
%
追踪进程解决的一个根本问题是：

当读入了新的关键帧之后，原来我在重建过程中提取的3维空间中的特征点现在在照片中的坐标是什么？我现在的相机z姿态怎么估计？ 

给定 

\subsubsection{关键特征点的投影和配对}

我们假定程序可以从映射进程得到一个关键帧集合 $Img$ 以及3维重建的特征点的坐标集合(相对于世界坐标系)$P=P_\itW=\{\bfp_{1\itW},\ldots,\bfp_{s\itW}\}$，为了统一形式，将第$j$个点坐标记为 $\bfp_{j\itW}= (p_{jx},p_{jy},p_{jz},1)$。

根据已知结论，坐标系变换对应公式为

\begin{equation}
\bfp_{jK_{t+1}}= E_{K_{t+1}\itW} \bfp_{j\itW}
\end{equation}

下面





\subsubsection{相机模型参数的求解和位置的更新}


为了保证算法的稳定性，追踪进程会进行两次：第一次会从三维模型中抽取50个特征点投影匹配，第二次则抽取1000个特征点进行匹配。


\subsection{PTAM管线之二: Mapping}

\subsubsection{关键帧的选择和插入}

\subsubsection{利用Bundle Adjustment极小化误差}


\section{PTAM算法的实际应用}
\subsection{在一般电脑上运行}
\subsection{在智能手机上运行}

\section{PTAM算法的评价}
